{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "895cb286",
   "metadata": {},
   "source": [
    "Show Parquet / Pyarrow API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b068d525",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f46ec68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:06.830747Z",
     "start_time": "2023-02-06T01:41:06.824259Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "_LOG = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "215ff89e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:06.844747Z",
     "start_time": "2023-02-06T01:41:06.834971Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_df() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create pandas random data, like:\n",
    "\n",
    "    ```\n",
    "                idx instr  val1  val2\n",
    "    2000-01-01    0     A    99    30\n",
    "    2000-01-02    0     A    54    46\n",
    "    2000-01-03    0     A    85    86\n",
    "    ```\n",
    "    \"\"\"\n",
    "    instruments = \"A B C D E\".split()\n",
    "    \"id stock val1 val2\".split()\n",
    "    df_idx = pd.date_range(\n",
    "        pd.Timestamp(\"2000-01-01\"), pd.Timestamp(\"2000-01-15\"), freq=\"1D\"\n",
    "    )\n",
    "    # print(df_idx)\n",
    "    random.seed(1000)\n",
    "\n",
    "    df = []\n",
    "    for idx, inst in enumerate(instruments):\n",
    "        df_tmp = pd.DataFrame(\n",
    "            {\n",
    "                \"idx\": idx,\n",
    "                \"instr\": inst,\n",
    "                \"val1\": [random.randint(0, 100) for k in range(len(df_idx))],\n",
    "                \"val2\": [random.randint(0, 100) for k in range(len(df_idx))],\n",
    "            },\n",
    "            index=df_idx,\n",
    "        )\n",
    "        # print(df_tmp)\n",
    "        df.append(df_tmp)\n",
    "    df = pd.concat(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e8235d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:06.855431Z",
     "start_time": "2023-02-06T01:41:06.848644Z"
    }
   },
   "outputs": [],
   "source": [
    "def df_to_str(df: pd.DataFrame) -> str:\n",
    "    txt = \"\"\n",
    "    txt += \"# df=\\n%s\" % df.head(3)\n",
    "    txt += \"\\n# df.shape=\\n%s\" % str(df.shape)\n",
    "    txt += \"\\n# df.dtypes=\\n%s\" % str(df.dtypes)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cc474b",
   "metadata": {},
   "source": [
    "# Save and load all data in one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb399156",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:06.875076Z",
     "start_time": "2023-02-06T01:41:06.859471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# df=\n",
      "            idx instr  val1  val2\n",
      "2000-01-01    0     A    99    30\n",
      "2000-01-02    0     A    54    46\n",
      "2000-01-03    0     A    85    86\n",
      "# df.shape=\n",
      "(75, 4)\n",
      "# df.dtypes=\n",
      "idx       int64\n",
      "instr    object\n",
      "val1      int64\n",
      "val2      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = get_df()\n",
    "# print(df.head())\n",
    "print(df_to_str(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "940dc7d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:06.886481Z",
     "start_time": "2023-02-06T01:41:06.878537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table=\n",
      "pyarrow.Table\n",
      "idx: int64\n",
      "instr: string\n",
      "val1: int64\n",
      "val2: int64\n",
      "__index_level_0__: timestamp[ns]\n",
      "----\n",
      "idx: [[0,0,0,0,0,...,4,4,4,4,4]]\n",
      "instr: [[\"A\",\"A\",\"A\",\"A\",\"A\",...,\"E\",\"E\",\"E\",\"E\",\"E\"]]\n",
      "val1: [[99,54,85,97,12,...,59,48,50,66,3]]\n",
      "val2: [[30,46,86,62,25,...,9,17,70,34,26]]\n",
      "__index_level_0__: [[2000-01-01 00:00:00.000000000,2000-01-02 00:00:00.000000000,2000-01-03 00:00:00.000000000,2000-01-04 00:00:00.000000000,2000-01-05 00:00:00.000000000,...,2000-01-11 00:00:00.000000000,2000-01-12 00:00:00.000000000,2000-01-13 00:00:00.000000000,2000-01-14 00:00:00.000000000,2000-01-15 00:00:00.000000000]]\n"
     ]
    }
   ],
   "source": [
    "table = pa.Table.from_pandas(df)\n",
    "\n",
    "print(\"table=\\n%s\" % table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93df67fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:06.941597Z",
     "start_time": "2023-02-06T01:41:06.890328Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save.\n",
    "file_name = \"df_in_one_file.pq\"\n",
    "pq.write_table(table, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "155e36c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:06.971319Z",
     "start_time": "2023-02-06T01:41:06.945301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow.Table\n",
      "idx: int64\n",
      "instr: string\n",
      "val1: int64\n",
      "val2: int64\n",
      "__index_level_0__: timestamp[us]\n",
      "----\n",
      "idx: [[0,0,0,0,0,...,4,4,4,4,4]]\n",
      "instr: [[\"A\",\"A\",\"A\",\"A\",\"A\",...,\"E\",\"E\",\"E\",\"E\",\"E\"]]\n",
      "val1: [[99,54,85,97,12,...,59,48,50,66,3]]\n",
      "val2: [[30,46,86,62,25,...,9,17,70,34,26]]\n",
      "__index_level_0__: [[2000-01-01 00:00:00.000000,2000-01-02 00:00:00.000000,2000-01-03 00:00:00.000000,2000-01-04 00:00:00.000000,2000-01-05 00:00:00.000000,...,2000-01-11 00:00:00.000000,2000-01-12 00:00:00.000000,2000-01-13 00:00:00.000000,2000-01-14 00:00:00.000000,2000-01-15 00:00:00.000000]]\n",
      "# df=\n",
      "            idx instr  val1  val2\n",
      "2000-01-01    0     A    99    30\n",
      "2000-01-02    0     A    54    46\n",
      "2000-01-03    0     A    85    86\n",
      "# df.shape=\n",
      "(75, 4)\n",
      "# df.dtypes=\n",
      "idx       int64\n",
      "instr    object\n",
      "val1      int64\n",
      "val2      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load.\n",
    "df2 = pq.read_table(file_name)\n",
    "print(df2)\n",
    "\n",
    "df2 = df2.to_pandas()\n",
    "print(df_to_str(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1098757c",
   "metadata": {},
   "source": [
    "## Read a subset of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f4a652f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:06.991105Z",
     "start_time": "2023-02-06T01:41:06.974796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow.Table\n",
      "idx: int64\n",
      "val1: int64\n",
      "----\n",
      "idx: [[0,0,0,0,0,...,4,4,4,4,4]]\n",
      "val1: [[99,54,85,97,12,...,59,48,50,66,3]]\n",
      "# df=\n",
      "   idx  val1\n",
      "0    0    99\n",
      "1    0    54\n",
      "2    0    85\n",
      "# df.shape=\n",
      "(75, 2)\n",
      "# df.dtypes=\n",
      "idx     int64\n",
      "val1    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df2 = pq.read_table(file_name, columns=[\"idx\", \"val1\"])\n",
    "print(df2)\n",
    "\n",
    "df2 = df2.to_pandas()\n",
    "print(df_to_str(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012cebdb",
   "metadata": {},
   "source": [
    "## Partitioned dataset\n",
    "\n",
    "from https://arrow.apache.org/docs/python/dataset.html#reading-partitioned-data\n",
    "\n",
    "- A dataset can exploit a nested structure, where the sub-dir names hold information about which subset of the data is stored in that dir\n",
    "- E.g., \"Hive\" patitioning scheme \"key=vale\" dir names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca26642e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:07.014079Z",
     "start_time": "2023-02-06T01:41:06.995636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# df=\n",
      "            idx instr  val1  val2\n",
      "2000-01-01    0     A    99    30\n",
      "2000-01-02    0     A    54    46\n",
      "2000-01-03    0     A    85    86\n",
      "# df.shape=\n",
      "(75, 4)\n",
      "# df.dtypes=\n",
      "idx       int64\n",
      "instr    object\n",
      "val1      int64\n",
      "val2      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = get_df()\n",
    "print(df_to_str(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cae349f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:07.136984Z",
     "start_time": "2023-02-06T01:41:07.021972Z"
    }
   },
   "outputs": [],
   "source": [
    "base = \".\"\n",
    "dir_name = os.path.join(base, \"parquet_dataset_partitioned\")\n",
    "os.system(\"rm -rf %s\" % dir_name)\n",
    "\n",
    "pq.write_to_dataset(table, dir_name, partition_cols=[\"idx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd57116d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:07.467214Z",
     "start_time": "2023-02-06T01:41:07.140807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'idx=0'  'idx=1'  'idx=2'  'idx=3'  'idx=4'\r\n"
     ]
    }
   ],
   "source": [
    "!ls parquet_dataset_partitioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac82b5ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:07.499318Z",
     "start_time": "2023-02-06T01:41:07.469897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./parquet_dataset_partitioned/idx=0/6a4868ebbe7944f6b52b70eb78ee236c-0.parquet\n",
      "./parquet_dataset_partitioned/idx=1/6a4868ebbe7944f6b52b70eb78ee236c-0.parquet\n",
      "./parquet_dataset_partitioned/idx=2/6a4868ebbe7944f6b52b70eb78ee236c-0.parquet\n",
      "./parquet_dataset_partitioned/idx=3/6a4868ebbe7944f6b52b70eb78ee236c-0.parquet\n",
      "./parquet_dataset_partitioned/idx=4/6a4868ebbe7944f6b52b70eb78ee236c-0.parquet\n"
     ]
    }
   ],
   "source": [
    "# Read data back.\n",
    "dataset = ds.dataset(dir_name, format=\"parquet\", partitioning=\"hive\")\n",
    "\n",
    "print(\"\\n\".join(dataset.files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64394b7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:07.530278Z",
     "start_time": "2023-02-06T01:41:07.502188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# df=\n",
      "           instr  val1  val2  idx\n",
      "2000-01-01     A    99    30    0\n",
      "2000-01-02     A    54    46    0\n",
      "2000-01-03     A    85    86    0\n",
      "# df.shape=\n",
      "(75, 4)\n",
      "# df.dtypes=\n",
      "instr    object\n",
      "val1      int64\n",
      "val2      int64\n",
      "idx       int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Read everything.\n",
    "df2 = dataset.to_table().to_pandas()\n",
    "\n",
    "print(df_to_str(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df96e1db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:07.561716Z",
     "start_time": "2023-02-06T01:41:07.533138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# df=\n",
      "           instr  val1  val2  idx\n",
      "2000-01-01     B    18    22    1\n",
      "2000-01-02     B    59    89    1\n",
      "2000-01-03     B    91    90    1\n",
      "# df.shape=\n",
      "(15, 4)\n",
      "# df.dtypes=\n",
      "instr    object\n",
      "val1      int64\n",
      "val2      int64\n",
      "idx       int32\n",
      "dtype: object\n",
      "# df=\n",
      "           instr  val1  val2  idx\n",
      "2000-01-01     A    99    30    0\n",
      "2000-01-02     A    54    46    0\n",
      "2000-01-03     A    85    86    0\n",
      "# df.shape=\n",
      "(45, 4)\n",
      "# df.dtypes=\n",
      "instr    object\n",
      "val1      int64\n",
      "val2      int64\n",
      "idx       int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load part of the data.\n",
    "\n",
    "df2 = dataset.to_table(filter=ds.field(\"idx\") == 1).to_pandas()\n",
    "print(df_to_str(df2))\n",
    "\n",
    "df2 = dataset.to_table(filter=ds.field(\"idx\") < 3).to_pandas()\n",
    "print(df_to_str(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c27848",
   "metadata": {},
   "source": [
    "## Add year-month partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69d2ea15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:07.587704Z",
     "start_time": "2023-02-06T01:41:07.566203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# df=\n",
      "            idx instr  val1  val2  year  month\n",
      "2000-01-01    0     A    99    30  2000      1\n",
      "2000-01-02    0     A    54    46  2000      1\n",
      "2000-01-03    0     A    85    86  2000      1\n",
      "# df.shape=\n",
      "(75, 6)\n",
      "# df.dtypes=\n",
      "idx       int64\n",
      "instr    object\n",
      "val1      int64\n",
      "val2      int64\n",
      "year      int64\n",
      "month     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = get_df()\n",
    "df[\"year\"] = df.index.year\n",
    "df[\"month\"] = df.index.month\n",
    "\n",
    "print(df_to_str(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a2f8c3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:07.601271Z",
     "start_time": "2023-02-06T01:41:07.591983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table=\n",
      "pyarrow.Table\n",
      "idx: int64\n",
      "instr: string\n",
      "val1: int64\n",
      "val2: int64\n",
      "year: int64\n",
      "month: int64\n",
      "__index_level_0__: timestamp[ns]\n",
      "----\n",
      "idx: [[0,0,0,0,0,...,4,4,4,4,4]]\n",
      "instr: [[\"A\",\"A\",\"A\",\"A\",\"A\",...,\"E\",\"E\",\"E\",\"E\",\"E\"]]\n",
      "val1: [[99,54,85,97,12,...,59,48,50,66,3]]\n",
      "val2: [[30,46,86,62,25,...,9,17,70,34,26]]\n",
      "year: [[2000,2000,2000,2000,2000,...,2000,2000,2000,2000,2000]]\n",
      "month: [[1,1,1,1,1,...,1,1,1,1,1]]\n",
      "__index_level_0__: [[2000-01-01 00:00:00.000000000,2000-01-02 00:00:00.000000000,2000-01-03 00:00:00.000000000,2000-01-04 00:00:00.000000000,2000-01-05 00:00:00.000000000,...,2000-01-11 00:00:00.000000000,2000-01-12 00:00:00.000000000,2000-01-13 00:00:00.000000000,2000-01-14 00:00:00.000000000,2000-01-15 00:00:00.000000000]]\n"
     ]
    }
   ],
   "source": [
    "table = pa.Table.from_pandas(df)\n",
    "\n",
    "print(\"table=\\n%s\" % table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9112ed65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:07.742652Z",
     "start_time": "2023-02-06T01:41:07.604571Z"
    }
   },
   "outputs": [],
   "source": [
    "base = \".\"\n",
    "dir_name = os.path.join(base, \"pq_partitioned2\")\n",
    "os.system(\"rm -rf %s\" % dir_name)\n",
    "\n",
    "pq.write_to_dataset(table, dir_name, partition_cols=[\"idx\", \"year\", \"month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "844913cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:08.066843Z",
     "start_time": "2023-02-06T01:41:07.745667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'idx=0'  'idx=1'  'idx=2'  'idx=3'  'idx=4'\r\n"
     ]
    }
   ],
   "source": [
    "!ls $dir_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5ba8be3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:08.408269Z",
     "start_time": "2023-02-06T01:41:08.070804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11f5e2911e294dd8882e3fb14a035ba2-0.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!ls $dir_name/idx=0/year=2000/month=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d93f116",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:08.455723Z",
     "start_time": "2023-02-06T01:41:08.411222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./pq_partitioned2/idx=0/year=2000/month=1/11f5e2911e294dd8882e3fb14a035ba2-0.parquet\n",
      "./pq_partitioned2/idx=1/year=2000/month=1/11f5e2911e294dd8882e3fb14a035ba2-0.parquet\n",
      "./pq_partitioned2/idx=2/year=2000/month=1/11f5e2911e294dd8882e3fb14a035ba2-0.parquet\n",
      "./pq_partitioned2/idx=3/year=2000/month=1/11f5e2911e294dd8882e3fb14a035ba2-0.parquet\n",
      "./pq_partitioned2/idx=4/year=2000/month=1/11f5e2911e294dd8882e3fb14a035ba2-0.parquet\n"
     ]
    }
   ],
   "source": [
    "# Read data back.\n",
    "dataset = ds.dataset(dir_name, format=\"parquet\", partitioning=\"hive\")\n",
    "\n",
    "print(\"\\n\".join(dataset.files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "21148afd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:08.495054Z",
     "start_time": "2023-02-06T01:41:08.458405Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# df=\n",
      "           instr  val1  val2  idx  year  month\n",
      "2000-01-01     C    99    37    2  2000      1\n",
      "2000-01-02     C    98    48    2  2000      1\n",
      "2000-01-03     C    70    58    2  2000      1\n",
      "# df.shape=\n",
      "(15, 6)\n",
      "# df.dtypes=\n",
      "instr    object\n",
      "val1      int64\n",
      "val2      int64\n",
      "idx       int32\n",
      "year      int32\n",
      "month     int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Read data back.\n",
    "dataset = ds.dataset(dir_name, format=\"parquet\", partitioning=\"hive\")\n",
    "\n",
    "df2 = dataset.to_table(filter=ds.field(\"idx\") == 2).to_pandas()\n",
    "print(df_to_str(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9e4e596",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:08.832605Z",
     "start_time": "2023-02-06T01:41:08.498195Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: int64\n",
      "instr: string\n",
      "val1: int64\n",
      "val2: int64\n",
      "year: int64\n",
      "month: int64\n",
      "__index_level_0__: timestamp[ns]\n",
      "-- schema metadata --\n",
      "pandas: '{\"index_columns\": [\"__index_level_0__\"], \"column_indexes\": [{\"na' + 976\n"
     ]
    }
   ],
   "source": [
    "# We could scan manually and create the dirs manually if we don't want to add\n",
    "# add a new dir.\n",
    "base = \".\"\n",
    "dir_name = os.path.join(base, \"parquet_dataset_partitioned2\")\n",
    "os.system(\"rm -rf %s\" % dir_name)\n",
    "\n",
    "schemas = []\n",
    "\n",
    "schema = pa.Table.from_pandas(df).schema\n",
    "print(schema)\n",
    "# assert 0\n",
    "# idx: int64\n",
    "# instr: string\n",
    "# val1: int64\n",
    "# val2: int64\n",
    "# year: int64\n",
    "# month: int64\n",
    "\n",
    "# grouped = df.groupby(lambda x: x.day)\n",
    "group_by_idx = df.groupby(\"idx\")\n",
    "for idx, df_tmp in group_by_idx:\n",
    "    _LOG.debug(\"idx=%s -> df.shape=%s\", idx, str(df_tmp.shape))\n",
    "    #\n",
    "    group_by_year = df_tmp.groupby(lambda x: x.year)\n",
    "    for year, df_tmp2 in group_by_year:\n",
    "        _LOG.debug(\"year=%s -> df.shape=%s\", year, str(df_tmp2.shape))\n",
    "        #\n",
    "        group_by_month = df_tmp2.groupby(lambda x: x.month)\n",
    "        for month, df_tmp3 in group_by_month:\n",
    "            _LOG.debug(\"month=%s -> df.shape=%s\", month, str(df_tmp3.shape))\n",
    "            # file_name = \"df_in_one_file.pq\"\n",
    "            # pq.write_table(table, file_name)\n",
    "            # /app/data/idx=0/year=2000/month=1/02e3265d515e4fb88ebe1a72a405fc05.parquet\n",
    "            subdir_name = os.path.join(\n",
    "                dir_name, f\"idx={idx}\", f\"year={year}\", f\"month={month}\"\n",
    "            )\n",
    "            table = pa.Table.from_pandas(df_tmp3, schema=schema)\n",
    "            schemas.append(table.schema)\n",
    "            # print(df_tmp3)\n",
    "            # print(table.schema)\n",
    "            #             pq.write_to_dataset(table,\n",
    "            #                     subdir_name, schema=schema)\n",
    "            file_name = os.path.join(subdir_name, \"df_out.pq\")\n",
    "            #hio.create_enclosing_dir(file_name)\n",
    "            os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "            pq.write_table(table, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5bdcdd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:08.838179Z",
     "start_time": "2023-02-06T01:41:08.834690Z"
    }
   },
   "outputs": [],
   "source": [
    "#!ls $dir_name/idx=0/year=2000/month=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aaf67ae6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:08.910364Z",
     "start_time": "2023-02-06T01:41:08.841344Z"
    }
   },
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Unable to merge: Field month has incompatible types: int64 vs int32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read data back.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# https://github.com/dask/dask/issues/4194\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# src_dir = f\"{dir_name}/idx=0/year=2000/month=1\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m src_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdir_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/idx=0/year=2000\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhive\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m df2 \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mto_table()\u001b[38;5;241m.\u001b[39mto_pandas()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# print(df_to_str(df2))\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyarrow/dataset.py:762\u001b[0m, in \u001b[0;36mdataset\u001b[0;34m(source, schema, format, filesystem, partitioning, partition_base_dir, exclude_invalid_files, ignore_prefixes)\u001b[0m\n\u001b[1;32m    751\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    752\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[1;32m    753\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    758\u001b[0m     selector_ignore_prefixes\u001b[38;5;241m=\u001b[39mignore_prefixes\n\u001b[1;32m    759\u001b[0m )\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_path_like(source):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_filesystem_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(source, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_path_like(elem) \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m source):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyarrow/dataset.py:455\u001b[0m, in \u001b[0;36m_filesystem_dataset\u001b[0;34m(source, schema, filesystem, partitioning, format, partition_base_dir, exclude_invalid_files, selector_ignore_prefixes)\u001b[0m\n\u001b[1;32m    447\u001b[0m options \u001b[38;5;241m=\u001b[39m FileSystemFactoryOptions(\n\u001b[1;32m    448\u001b[0m     partitioning\u001b[38;5;241m=\u001b[39mpartitioning,\n\u001b[1;32m    449\u001b[0m     partition_base_dir\u001b[38;5;241m=\u001b[39mpartition_base_dir,\n\u001b[1;32m    450\u001b[0m     exclude_invalid_files\u001b[38;5;241m=\u001b[39mexclude_invalid_files,\n\u001b[1;32m    451\u001b[0m     selector_ignore_prefixes\u001b[38;5;241m=\u001b[39mselector_ignore_prefixes\n\u001b[1;32m    452\u001b[0m )\n\u001b[1;32m    453\u001b[0m factory \u001b[38;5;241m=\u001b[39m FileSystemDatasetFactory(fs, paths_or_selector, \u001b[38;5;28mformat\u001b[39m, options)\n\u001b[0;32m--> 455\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfactory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyarrow/_dataset.pyx:2062\u001b[0m, in \u001b[0;36mpyarrow._dataset.DatasetFactory.finish\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyarrow/error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Unable to merge: Field month has incompatible types: int64 vs int32"
     ]
    }
   ],
   "source": [
    "# Read data back.\n",
    "# https://github.com/dask/dask/issues/4194\n",
    "# src_dir = f\"{dir_name}/idx=0/year=2000/month=1\"\n",
    "src_dir = f\"{dir_name}/idx=0/year=2000\"\n",
    "dataset = ds.dataset(src_dir, format=\"parquet\", partitioning=\"hive\")\n",
    "\n",
    "df2 = dataset.to_table().to_pandas()\n",
    "# print(df_to_str(df2))\n",
    "print(\"\\n\".join(dataset.files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f4111d",
   "metadata": {},
   "source": [
    "## Partition manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b33d85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:08.914146Z",
     "start_time": "2023-02-06T01:41:08.914124Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyarrow.dataset import DirectoryPartitioning\n",
    "\n",
    "partitioning = DirectoryPartitioning(\n",
    "    pa.schema([(\"year\", pa.int16()), (\"month\", pa.int8()), (\"day\", pa.int8())])\n",
    ")\n",
    "print(partitioning.parse(\"/2009/11/3\"))\n",
    "\n",
    "# partitioning.discover()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad70cbee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:08.915786Z",
     "start_time": "2023-02-06T01:41:08.915765Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls /data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d1189",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:08.919226Z",
     "start_time": "2023-02-06T01:41:08.919204Z"
    }
   },
   "outputs": [],
   "source": [
    "dir_name = \"/app/data\"\n",
    "\n",
    "# Read data back.\n",
    "dataset = ds.dataset(dir_name, format=\"parquet\", partitioning=\"hive\")\n",
    "\n",
    "print(\"\\n\".join(dataset.files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4d7dc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:08.923300Z",
     "start_time": "2023-02-06T01:41:08.923277Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read everything.\n",
    "df2 = dataset.to_table().to_pandas()\n",
    "\n",
    "print(df_to_str(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e84388",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T01:41:08.927845Z",
     "start_time": "2023-02-06T01:41:08.927822Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df2[\"instr\"].unique())\n",
    "print(df2.index)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.3",
    "jupytext_version": "1.11.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "205.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
